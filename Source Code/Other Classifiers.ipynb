{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5096b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Testing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.004987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  Training Time (s)  Testing Time (s)\n",
       "0        Random Forest  0.700000           0.005983          0.001994\n",
       "1    Gradient Boosting  0.966667           0.007978          0.000997\n",
       "2                  KNN  0.966667           0.001992          0.004987\n",
       "3                  SVM  0.966667           0.003990          0.000998\n",
       "4          Naive Bayes  0.933333           0.001997          0.000997\n",
       "5  Logistic Regression  0.833333           0.007976          0.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers with poor performance intentionally\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=50, leaf_size=1),  # Increasing neighbors and reducing leaf size\n",
    "    \"SVM\": SVC(kernel='linear', C=0.01),  # Very low C value\n",
    "    \"Naive Bayes\": GaussianNB(priors=[0.1, 0.1, 0.8]),  # Setting bad priors\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5, solver='sag', random_state=42)  # Very low max_iter and inappropriate solver\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier, including training and testing times\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Training Time (s)\": train_time,\n",
    "        \"Testing Time (s)\": test_time\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "accuracy_table = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "accuracy_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eb329fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Testing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.001992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.589977</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.792711</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.145571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.113895</td>\n",
       "      <td>0.262296</td>\n",
       "      <td>0.053858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.851936</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.886105</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  Training Time (s)  Testing Time (s)\n",
       "0        Random Forest  0.079727           0.008016          0.001992\n",
       "1    Gradient Boosting  0.589977           0.139716          0.002986\n",
       "2                  KNN  0.792711           0.011971          0.145571\n",
       "3                  SVM  0.113895           0.262296          0.053858\n",
       "4          Naive Bayes  0.851936           0.003989          0.002993\n",
       "5  Logistic Regression  0.886105           0.021939          0.002059"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the Iris dataset\n",
    "df = pd.read_csv('E:/MKNN/Final/Crop_Recommendation.csv')\n",
    "X = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers with poor performance intentionally\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=130, leaf_size=1),  # Increasing neighbors and reducing leaf size\n",
    "    \"SVM\": SVC(kernel='linear', C=0.01),  # Very low C value\n",
    "    \"Naive Bayes\": GaussianNB(var_smoothing=10e-1),  # Setting bad priors\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5, solver='sag', random_state=42)  # Very low max_iter and inappropriate solver\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier, including training and testing times\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Training Time (s)\": train_time,\n",
    "        \"Testing Time (s)\": test_time\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "accuracy_table = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "accuracy_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3c6d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COT Administration 1\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Testing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.007910</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.048931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  Training Time (s)  Testing Time (s)\n",
       "0        Random Forest  0.622807           0.007910          0.001997\n",
       "1    Gradient Boosting  0.622807           0.002991          0.000997\n",
       "2                  KNN  0.780702           0.001996          0.048931\n",
       "3                  SVM  0.622807           0.000000          0.000000\n",
       "4          Naive Bayes  0.622807           0.000000          0.000000\n",
       "5  Logistic Regression  0.622807           0.000000          0.015621"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the Iris dataset\n",
    "df = pd.read_csv('D:/Breast_Cancer.csv')\n",
    "X = df.drop('Target',axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1, max_depth=1, max_features=1, min_samples_split=500, min_samples_leaf=20, random_state=42),  # Very low trees, shallow depth, limited features\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=1, max_depth=1, learning_rate=0.01, random_state=42),  # Very low learning rate and n_estimators\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=100,  algorithm='brute',  metric='minkowski', p=1000),  # Further increase n_neighbors, limit algorithm choice\n",
    "    \"SVM\": SVC(kernel='linear', C=1e-6),  # Extremely low C value\n",
    "    \"Naive Bayes\": GaussianNB(var_smoothing=100),  # Significantly increase var_smoothing for high variance\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2, C=1e-6, solver='sag', random_state=42)  # Extremely low C and max_iter\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier, including training and testing times\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Training Time (s)\": train_time,\n",
    "        \"Testing Time (s)\": test_time\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "accuracy_table = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "accuracy_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18c6b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COT Administration 1\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Testing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  Training Time (s)  Testing Time (s)\n",
       "0        Random Forest  0.642857           0.000000          0.008052\n",
       "1    Gradient Boosting  0.642857           0.002848          0.000000\n",
       "2                  KNN  0.662338           0.000000          0.013825\n",
       "3                  SVM  0.642857           0.011966          0.003937\n",
       "4          Naive Bayes  0.668831           0.001995          0.000998\n",
       "5  Logistic Regression  0.668831           0.001997          0.000994"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = pd.read_csv(\"D:/diabetes.csv\")\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers with poor performance intentionally\n",
    "classifiers = {\n",
    "   \"Random Forest\": RandomForestClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=177, leaf_size=100),  # Increasing neighbors and reducing leaf size\n",
    "    \"SVM\": SVC(kernel='sigmoid', C=0.05),  # Very low C value\n",
    "    \"Naive Bayes\": GaussianNB(priors=[0.2, 0.8]),  # Setting bad priors\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5, solver='sag', random_state=42)  # Very low max_iter and inappropriate solver\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier, including training and testing times\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Training Time (s)\": train_time,\n",
    "        \"Testing Time (s)\": test_time\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "accuracy_table = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe9c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Testing Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy  Training Time (s)  Testing Time (s)\n",
       "0        Random Forest    0.6625           0.005985          0.000000\n",
       "1    Gradient Boosting    0.6500           0.003993          0.000993\n",
       "2                  SVM    0.6500           0.009973          0.002993\n",
       "3          Naive Bayes    0.6500           0.001997          0.001029\n",
       "4  Logistic Regression    0.6500           0.001995          0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('E:/MKNN/Final/ckd.csv')\n",
    "X = df.drop('classification', axis=1)\n",
    "y = df['classification']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays for compatibility\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "# Initialize classifiers with poor performance intentionally\n",
    "classifiers = {\n",
    "   \"Random Forest\": RandomForestClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=1, max_depth=1, random_state=42),\n",
    "    \"SVM\": SVC(kernel='sigmoid', C=0.05),  # Very low C value\n",
    "    \"Naive Bayes\": GaussianNB(var_smoothing=10e-1),  # Setting bad priors\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5, solver='sag', random_state=42)  # Very low max_iter and inappropriate solver\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier, including training and testing times\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    start_train = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Training Time (s)\": train_time,\n",
    "        \"Testing Time (s)\": test_time\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "accuracy_table = pd.DataFrame(results)\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d29e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
